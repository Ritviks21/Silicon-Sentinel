{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ritviks21/Silicon-Sentinel/blob/main/Silicon_Sentinel_Training_ipynb_just_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "iftMO8vuBDVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Xobvpv_y5A86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Libraries"
      ],
      "metadata": {
        "id": "93_2HeESC3Me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics opencv-python n"
      ],
      "metadata": {
        "id": "T-z5fGbT5Fzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Data Generation Script"
      ],
      "metadata": {
        "id": "j6OKNb2Q237l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import math\n",
        "\n",
        "# --- Configuration ---\n",
        "DATASET_PATH = 'ultimate_wafer_dataset'\n",
        "NUM_IMAGES = 2500\n",
        "IMG_WIDTH = 640\n",
        "IMG_HEIGHT = 640\n",
        "defect_classes = {\"scratch\": 0, \"particle\": 1, \"blob\": 2}\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def create_base_wafer():\n",
        "    \"\"\"\n",
        "    Creates a more realistic, textured silicon wafer background with variations\n",
        "    to prevent the model from overfitting to a single background pattern.\n",
        "    \"\"\"\n",
        "    bg_type = random.choice(['smooth', 'grainy', 'gradient'])\n",
        "    base_color = random.randint(45, 60)\n",
        "    image = np.full((IMG_HEIGHT, IMG_WIDTH, 3), base_color, dtype=np.uint8)\n",
        "\n",
        "    if bg_type == 'grainy':\n",
        "        noise = np.random.normal(0, 3, (IMG_HEIGHT, IMG_WIDTH, 3)).astype(np.int16)\n",
        "        image = np.clip(image.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
        "        image = cv2.GaussianBlur(image, (3, 3), 0)\n",
        "    elif bg_type == 'gradient':\n",
        "        end_color = base_color - random.randint(10, 20)\n",
        "        c = np.linspace(base_color, end_color, IMG_WIDTH, dtype=np.uint8)\n",
        "        image[:, :, :] = c[np.newaxis, :, np.newaxis]\n",
        "\n",
        "    # Add a subtle color tint to mimic silicon\n",
        "    tint_color = np.array([1.0, 1.0, random.uniform(1.0, 1.05)])\n",
        "    image = np.clip(image * tint_color, 0, 255).astype(np.uint8)\n",
        "    return image\n",
        "\n",
        "def add_advanced_scratch(image):\n",
        "    \"\"\"\n",
        "    Generates straight, curved, or wavy scratches to teach the model to\n",
        "    differentiate from simple background lines.\n",
        "    \"\"\"\n",
        "    start_x, start_y = random.randint(50, IMG_WIDTH - 50), random.randint(50, IMG_HEIGHT - 50)\n",
        "    thickness, color = random.randint(1, 2), (random.randint(220, 255),) * 3\n",
        "    points = [(start_x, start_y)]\n",
        "    scratch_type = random.choice(['straight', 'curved', 'wavy'])\n",
        "    if scratch_type == 'straight':\n",
        "        end_x, end_y = start_x + random.randint(-200, 200), start_y + random.randint(-200, 200)\n",
        "        points.append((end_x, end_y))\n",
        "    elif scratch_type == 'curved':\n",
        "        end_x, end_y = start_x + random.randint(-200, 200), start_y + random.randint(-200, 200)\n",
        "        ctrl_x = (start_x + end_x) // 2 + random.randint(-50, 50)\n",
        "        ctrl_y = (start_y + end_y) // 2 + random.randint(-50, 50)\n",
        "        for i in range(1, 21):\n",
        "            t = i / 20.0\n",
        "            x = int((1 - t)**2 * start_x + 2 * (1 - t) * t * ctrl_x + t**2 * end_x)\n",
        "            y = int((1 - t)**2 * start_y + 2 * (1 - t) * t * ctrl_y + t**2 * end_y)\n",
        "            points.append((x,y))\n",
        "    elif scratch_type == 'wavy':\n",
        "        length, angle = random.randint(100, 300), random.uniform(0, 2 * math.pi)\n",
        "        freq, amp = random.uniform(0.02, 0.05), random.uniform(5, 15)\n",
        "        for i in range(length):\n",
        "            x = start_x + int(i * math.cos(angle) - amp * math.sin(i * freq) * math.sin(angle))\n",
        "            y = start_y + int(i * math.sin(angle) + amp * math.sin(i * freq) * math.cos(angle))\n",
        "            points.append((x,y))\n",
        "\n",
        "    for i in range(len(points) - 1):\n",
        "        if 0 <= points[i][0] < IMG_WIDTH and 0 <= points[i][1] < IMG_HEIGHT and \\\n",
        "           0 <= points[i+1][0] < IMG_WIDTH and 0 <= points[i+1][1] < IMG_HEIGHT:\n",
        "            cv2.line(image, points[i], points[i+1], color, thickness)\n",
        "\n",
        "    all_x = [p[0] for p in points]; all_y = [p[1] for p in points]\n",
        "    x_min, x_max = min(all_x), max(all_x)\n",
        "    y_min, y_max = min(all_y), max(all_y)\n",
        "    x_center, y_center = (x_min + x_max) / 2, (y_min + y_max) / 2\n",
        "    width, height = x_max - x_min, y_max - y_min\n",
        "\n",
        "    return image, [defect_classes[\"scratch\"], x_center / IMG_WIDTH, y_center / IMG_HEIGHT, width / IMG_WIDTH, height / IMG_HEIGHT]\n",
        "\n",
        "\n",
        "def add_distinct_particles(image):\n",
        "    \"\"\"\n",
        "    Adds small, sharp, bright 'dust' specks to solve class confusion and\n",
        "    improve detection of small objects.\n",
        "    \"\"\"\n",
        "    num_particles = random.randint(1, 15)\n",
        "    all_x, all_y = [], []\n",
        "    for _ in range(num_particles):\n",
        "        px, py = random.randint(20, IMG_WIDTH - 20), random.randint(20, IMG_HEIGHT - 20)\n",
        "        radius = random.randint(1, 2)\n",
        "        color = (random.randint(230, 255),) * 3\n",
        "        cv2.circle(image, (px, py), radius, color, -1)\n",
        "        all_x.extend([px - radius, px + radius]); all_y.extend([py - radius, py + radius])\n",
        "\n",
        "    x_min, x_max, y_min, y_max = min(all_x), max(all_x), min(all_y), max(all_y)\n",
        "    x_center, y_center = (x_min + x_max) / 2, (y_min + y_max) / 2\n",
        "    width, height = x_max - x_min, y_max - y_min\n",
        "    return image, [defect_classes[\"particle\"], x_center / IMG_WIDTH, y_center / IMG_HEIGHT, width / IMG_WIDTH, height / IMG_HEIGHT]\n",
        "\n",
        "def add_distinct_blob(image):\n",
        "    \"\"\"\n",
        "    Adds a larger, irregular, transparent 'smudge' to solve class confusion.\n",
        "    \"\"\"\n",
        "    overlay, output = image.copy(), image.copy()\n",
        "    center_x, center_y = random.randint(150, IMG_WIDTH - 150), random.randint(150, IMG_HEIGHT - 150)\n",
        "\n",
        "    num_points = random.randint(5, 10)\n",
        "    angles = sorted([random.uniform(0, 2 * math.pi) for _ in range(num_points)])\n",
        "    points = []\n",
        "    for angle in angles:\n",
        "        radius = random.uniform(40, 80)\n",
        "        x = center_x + int(radius * math.cos(angle))\n",
        "        y = center_y + int(radius * math.sin(angle))\n",
        "        points.append([x, y])\n",
        "    points = np.array(points, np.int32)\n",
        "\n",
        "    color = (random.randint(80, 100),) * 3\n",
        "    cv2.fillPoly(overlay, [points], color)\n",
        "    overlay = cv2.GaussianBlur(overlay, (21, 21), 0)\n",
        "\n",
        "    transparency = random.uniform(0.2, 0.5)\n",
        "    cv2.addWeighted(overlay, transparency, output, 1 - transparency, 0, image)\n",
        "\n",
        "    all_x, all_y = points[:, 0], points[:, 1]\n",
        "    x_min, x_max, y_min, y_max = min(all_x), max(all_x), min(all_y), max(all_y)\n",
        "    x_center, y_center = (x_min + x_max) / 2, (y_min + y_max) / 2\n",
        "    width, height = x_max - x_min, y_max - y_min\n",
        "    return image, [defect_classes[\"blob\"], x_center / IMG_WIDTH, y_center / IMG_HEIGHT, width / IMG_WIDTH, height / IMG_HEIGHT]\n",
        "\n",
        "# --- Main Generation Function ---\n",
        "def generate_ultimate_dataset():\n",
        "    images_path = os.path.join(DATASET_PATH, 'images')\n",
        "    labels_path = os.path.join(DATASET_PATH, 'labels')\n",
        "    if os.path.exists(DATASET_PATH): shutil.rmtree(DATASET_PATH)\n",
        "    os.makedirs(images_path, exist_ok=True); os.makedirs(labels_path, exist_ok=True)\n",
        "    print(f\"Directories created at: {os.path.abspath(DATASET_PATH)}\")\n",
        "    for i in range(NUM_IMAGES):\n",
        "        wafer_image, annotations = create_base_wafer(), []\n",
        "        if random.random() >= 0.25: # 25% of images will be clean \"negative\" samples\n",
        "            for _ in range(random.randint(1, 4)):\n",
        "                defect_type = random.choice(list(defect_classes.keys()))\n",
        "                if defect_type == \"scratch\": wafer_image, ann = add_advanced_scratch(wafer_image)\n",
        "                elif defect_type == \"particle\": wafer_image, ann = add_distinct_particles(wafer_image)\n",
        "                else: wafer_image, ann = add_distinct_blob(wafer_image)\n",
        "                if ann and ann[3] > 0 and ann[4] > 0: annotations.append(ann)\n",
        "        img_name, label_name = f'wafer_{i:04d}.png', f'wafer_{i:04d}.txt'\n",
        "        cv2.imwrite(os.path.join(images_path, img_name), wafer_image)\n",
        "        with open(os.path.join(labels_path, label_name), 'w') as f:\n",
        "            for ann in annotations: f.write(f\"{ann[0]} {ann[1]} {ann[2]} {ann[3]} {ann[4]}\\n\")\n",
        "        if (i + 1) % 250 == 0: print(f\"  -> Generated {i + 1}/{NUM_IMAGES} images...\")\n",
        "    print(f\"\\n‚úÖ Ultimate dataset generation complete!\")\n",
        "\n",
        "generate_ultimate_dataset()"
      ],
      "metadata": {
        "id": "KafpKd4e5L3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the Ultimate Dataset"
      ],
      "metadata": {
        "id": "43aAqf3_3W-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# --- Configuration ---\n",
        "DATA_SOURCE_DIR = 'ultimate_wafer_dataset'\n",
        "OUTPUT_DIR = 'ultimate_data_for_training'\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.2\n",
        "\n",
        "# --- Splitting Logic ---\n",
        "images_source_path = os.path.join(DATA_SOURCE_DIR, 'images')\n",
        "all_images = [f for f in os.listdir(images_source_path) if f.endswith('.png')]\n",
        "random.shuffle(all_images)\n",
        "\n",
        "total_images = len(all_images)\n",
        "train_end = int(total_images * TRAIN_RATIO)\n",
        "val_end = train_end + int(total_images * VAL_RATIO)\n",
        "\n",
        "train_files = all_images[:train_end]\n",
        "val_files = all_images[train_end:val_end]\n",
        "test_files = all_images[val_end:]\n",
        "\n",
        "def copy_files(file_list, set_name):\n",
        "    dest_images_path = os.path.join(OUTPUT_DIR, set_name, 'images')\n",
        "    dest_labels_path = os.path.join(OUTPUT_DIR, set_name, 'labels')\n",
        "    os.makedirs(dest_images_path, exist_ok=True)\n",
        "    os.makedirs(dest_labels_path, exist_ok=True)\n",
        "    source_images_path = os.path.join(DATA_SOURCE_DIR, 'images')\n",
        "    source_labels_path = os.path.join(DATA_SOURCE_DIR, 'labels')\n",
        "    for filename in file_list:\n",
        "        base_name = os.path.splitext(filename)[0]\n",
        "        shutil.copy(os.path.join(source_images_path, filename), os.path.join(dest_images_path, filename))\n",
        "        shutil.copy(os.path.join(source_labels_path, f'{base_name}.txt'), os.path.join(dest_labels_path, f'{base_name}.txt'))\n",
        "    print(f\"  -> Copied {len(file_list)} files to the '{set_name}' set.\")\n",
        "\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "    shutil.rmtree(OUTPUT_DIR)\n",
        "copy_files(train_files, 'train')\n",
        "copy_files(val_files, 'val')\n",
        "copy_files(test_files, 'test')\n",
        "\n",
        "# --- Create YAML File ---\n",
        "yaml_content = f\"\"\"\n",
        "path: {os.path.abspath(OUTPUT_DIR)}\n",
        "train: train/images\n",
        "val: val/images\n",
        "test: test/images\n",
        "\n",
        "nc: 3\n",
        "names: ['scratch', 'particle', 'blob']\n",
        "\"\"\"\n",
        "with open(os.path.join(OUTPUT_DIR, 'data.yaml'), 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(f\"\\n‚úÖ Ultimate dataset successfully split.\")"
      ],
      "metadata": {
        "id": "Y6hkswTl5QZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Final Model"
      ],
      "metadata": {
        "id": "wSsM6-1t22wZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# --- Load the upgraded YOLOv8s model ---\n",
        "model = YOLO('yolov8s.pt')\n",
        "\n",
        "# --- Define the Google Drive save path ---\n",
        "drive_project_path = '/content/drive/MyDrive/wafer_project/wafer_final_runs'\n",
        "\n",
        "# --- Start the final training ---\n",
        "print(\"üöÄ Starting the FINAL model training with YOLOv8s, full augmentation, and 75 epochs...\")\n",
        "results = model.train(\n",
        "    data='ultimate_data_for_training/data.yaml',\n",
        "    epochs=75,         # Increased for better learning\n",
        "    imgsz=640,\n",
        "    degrees=15,        # Data augmentation\n",
        "    translate=0.1,\n",
        "    scale=0.1,\n",
        "    fliplr=0.5,\n",
        "    project=drive_project_path,\n",
        "    name='Silicon_Sentinel_v1.0' # Final model name\n",
        ")\n",
        "\n",
        "print(\"‚úÖ FINAL training complete!\")\n",
        "print(f\"Model and results are permanently saved in your Google Drive at: {results.save_dir}\")"
      ],
      "metadata": {
        "id": "dRa2rHDm5TJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Evaluation"
      ],
      "metadata": {
        "id": "GwcE4A9KkNBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# --- Unzip the test images ---\n",
        "print(\"Unzipping test images...\")\n",
        "!unzip -o test_images.zip -d test_images_unzipped\n",
        "print(\"‚úÖ Unzip complete.\")\n",
        "\n",
        "# --- Final Model Evaluation ---\n",
        "\n",
        "# 1. Path to our ultimate trained model in your Google Drive.\n",
        "model_path = '/content/drive/MyDrive/wafer_project/wafer_final_runs/Silicon_Sentinel_v1.0/weights/best.pt'\n",
        "\n",
        "# 2. Path to the test images folder.\n",
        "test_images_folder = 'test_images_unzipped/test_images'\n",
        "\n",
        "# 3. Load our final, powerful model.\n",
        "print(f\"\\nLoading Silicon Sentinel from: {model_path}\")\n",
        "model = YOLO(model_path)\n",
        "print(\"‚úÖ Final model loaded successfully.\")\n",
        "\n",
        "# 4. Run prediction with our strict 0.5 confidence threshold.\n",
        "print(\"\\nüöÄ Running FINAL predictions...\")\n",
        "results = model.predict(\n",
        "    source=test_images_folder,\n",
        "    save=True,\n",
        "    conf=0.5\n",
        ")\n",
        "print(\"‚úÖ Final predictions complete!\")\n",
        "\n",
        "# 5. Display the definitive results.\n",
        "prediction_output_dir = results[0].save_dir\n",
        "result_images = sorted(glob.glob(os.path.join(prediction_output_dir, '*.jpg')))\n",
        "\n",
        "if not result_images:\n",
        "    print(\"\\nCould not find any result images.\")\n",
        "else:\n",
        "    print(\"\\n--- ‚úÖ SILICON SENTINEL: FINAL RESULTS ---\")\n",
        "    for img_path in result_images:\n",
        "        print(f\"\\nResult for: {os.path.basename(img_path)}\")\n",
        "        display(Image(filename=img_path))"
      ],
      "metadata": {
        "id": "viGEOQps5dRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# --- Final Showcase Generation ---\n",
        "print(\"This is the final run. We will generate several sets of results for you to choose from.\")\n",
        "\n",
        "# The path to the ULTIMATE model, which is safely in your Google Drive\n",
        "model_path = '/content/drive/MyDrive/wafer_project/wafer_final_runs/Silicon_Sentinel_v1.0/weights/best.pt'\n",
        "test_images_folder = 'test_images_unzipped/test_images'\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"‚ùå ERROR: The final model was not found in your Google Drive at {model_path}\")\n",
        "else:\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # We will test at three different confidence levels\n",
        "    confidence_levels = [0.40, 0.25, 0.15]\n",
        "\n",
        "    for conf in confidence_levels:\n",
        "        print(f\"\\nüöÄ Running prediction with confidence threshold = {conf}...\")\n",
        "        model.predict(\n",
        "            source=test_images_folder,\n",
        "            save=True,\n",
        "            conf=conf,\n",
        "            name=f\"predict_at_{int(conf*100)}\" # Saves to a unique folder like 'predict_at_25'\n",
        "        )\n",
        "        print(f\"‚úÖ Prediction run for conf={conf} complete!\")\n",
        "\n",
        "print(\"\\n--- All showcase images have been generated. ---\")\n",
        "print(\"Please check the folders in 'runs/detect/' (e.g., 'predict_at_40', 'predict_at_25') to find your images.\")"
      ],
      "metadata": {
        "id": "Vr9P9tzx5iRp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}